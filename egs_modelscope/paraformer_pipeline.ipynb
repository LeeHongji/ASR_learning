{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This computer can only support the inference stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 08:10:31,169 - modelscope - INFO - Model revision not specified, use the latest revision: v1.2.1\n",
      "2023-09-01 08:10:31,465 - modelscope - INFO - initiate model from /home/lihongji/.cache/modelscope/hub/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-09-01 08:10:31,466 - modelscope - INFO - initiate model from location /home/lihongji/.cache/modelscope/hub/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch.\n",
      "2023-09-01 08:10:31,467 - modelscope - INFO - initialize model from /home/lihongji/.cache/modelscope/hub/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-09-01 08:10:31,470 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-01 08:10:31,470 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-01 08:10:31,471 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/lihongji/.cache/modelscope/hub/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch'}. trying to build by task and model information.\n",
      "2023-09-01 08:10:31,471 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "2023-09-01 08:10:51,766 - modelscope - INFO - Decoding with wav files ...\n",
      "2023-09-01 08:10:52,308 - modelscope - INFO - Computing the result of ASR ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '欢迎大家来体验达摩院推出的语音识别模型'}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch')\n",
    "\n",
    "rec_result = inference_pipeline(audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav')\n",
    "print(rec_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 10.9k/10.9k [00:00<00:00, 289kB/s]\n",
      "Downloading: 100%|██████████| 173k/173k [00:00<00:00, 1.23MB/s]\n",
      "Downloading: 100%|██████████| 55.5k/55.5k [00:00<00:00, 622kB/s]\n",
      "Downloading: 100%|██████████| 556/556 [00:00<00:00, 345kB/s]\n",
      "Downloading: 100%|██████████| 91.0/91.0 [00:00<00:00, 68.7kB/s]\n",
      "Downloading: 100%|██████████| 725/725 [00:00<00:00, 366kB/s]\n",
      "Downloading: 100%|██████████| 271M/271M [01:55<00:00, 2.45MB/s] \n",
      "Downloading: 100%|██████████| 8.28k/8.28k [00:00<00:00, 5.12MB/s]\n",
      "Downloading: 100%|██████████| 7.90M/7.90M [00:03<00:00, 2.35MB/s]\n",
      "Downloading: 100%|██████████| 48.7k/48.7k [00:00<00:00, 535kB/s]\n",
      "Downloading: 100%|██████████| 34.0k/34.0k [00:00<00:00, 775kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '欢'}\n",
      "{'text': '迎大'}\n",
      "{'text': '家来'}\n",
      "{'text': '体验'}\n",
      "{'text': '达摩院'}\n",
      "{'text': '推出'}\n",
      "{'text': '的语'}\n",
      "{'text': '音识'}\n",
      "{'text': '别模'}\n",
      "{'text': '型'}\n",
      "欢迎大家来体验达摩院推出的语音识别模型\n"
     ]
    }
   ],
   "source": [
    "# online streaming para\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import soundfile\n",
    "\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from modelscope.utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(log_level=logging.CRITICAL)\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = \"./\"\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8404-online',\n",
    "    model_revision='v1.0.6',\n",
    "    mode=\"paraformer_streaming\"\n",
    ")\n",
    "\n",
    "model_dir = os.path.join(os.environ[\"MODELSCOPE_CACHE\"], \"damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8404-online\")\n",
    "speech, sample_rate = soundfile.read(os.path.join(model_dir, \"example/asr_example.wav\"))\n",
    "speech_length = speech.shape[0]\n",
    "\n",
    "sample_offset = 0\n",
    "chunk_size = [8, 8, 4] #[5, 10, 5] 600ms, [8, 8, 4] 480ms\n",
    "stride_size =  chunk_size[1] * 960\n",
    "param_dict = {\"cache\": dict(), \"is_final\": False, \"chunk_size\": chunk_size}\n",
    "final_result = \"\"\n",
    "\n",
    "for sample_offset in range(0, speech_length, min(stride_size, speech_length - sample_offset)):\n",
    "    if sample_offset + stride_size >= speech_length - 1:\n",
    "        stride_size = speech_length - sample_offset\n",
    "        param_dict[\"is_final\"] = True\n",
    "    rec_result = inference_pipeline(audio_in=speech[sample_offset: sample_offset + stride_size],\n",
    "                                    param_dict=param_dict)\n",
    "    if len(rec_result) != 0:\n",
    "        final_result += rec_result['text']\n",
    "        print(rec_result)\n",
    "print(final_result.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
