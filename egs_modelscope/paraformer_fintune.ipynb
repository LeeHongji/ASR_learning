{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.metainfo import Trainers\n",
    "from modelscope.trainers import build_trainer\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "from funasr.datasets.ms_dataset import MsDataset\n",
    "from funasr.utils.compute_wer import compute_wer\n",
    "\n",
    "\n",
    "def modelscope_finetune(params):\n",
    "    if not os.path.exists(params[\"model_dir\"]):\n",
    "        os.makedirs(params[\"model_dir\"], exist_ok=True)\n",
    "    # dataset split [\"train\", \"validation\"]\n",
    "    ds_dict = MsDataset.load(params[\"dataset_path\"])\n",
    "    kwargs = dict(\n",
    "        model=params[\"modelscope_model_name\"],\n",
    "        data_dir=ds_dict,\n",
    "        dataset_type=params[\"dataset_type\"],\n",
    "        work_dir=params[\"model_dir\"],\n",
    "        batch_bins=params[\"batch_bins\"],\n",
    "        max_epoch=params[\"max_epoch\"],\n",
    "        lr=params[\"lr\"])\n",
    "    trainer = build_trainer(Trainers.speech_asr_trainer, default_args=kwargs)\n",
    "    trainer.train()\n",
    "    pretrained_model_path = os.path.join(os.environ[\"HOME\"], \".cache/modelscope/hub\", params[\"modelscope_model_name\"])\n",
    "    required_files = [\"am.mvn\", \"decoding.yaml\", \"configuration.json\"]\n",
    "    for file_name in required_files:\n",
    "        shutil.copy(os.path.join(pretrained_model_path, file_name),\n",
    "                    os.path.join(params[\"model_dir\"], file_name))\n",
    "    \n",
    "\n",
    "def modelscope_infer(params):\n",
    "    # prepare for decoding\n",
    "    with open(os.path.join(params[\"model_dir\"], \"configuration.json\")) as f:\n",
    "        config_dict = json.load(f)\n",
    "        config_dict[\"model\"][\"am_model_name\"] = params[\"decoding_model_name\"]\n",
    "    with open(os.path.join(params[\"model_dir\"], \"configuration.json\"), \"w\") as f:\n",
    "        json.dump(config_dict, f, indent=4, separators=(',', ': '))\n",
    "    decoding_path = os.path.join(params[\"model_dir\"], \"decode_results\")\n",
    "    if os.path.exists(decoding_path):\n",
    "        shutil.rmtree(decoding_path)\n",
    "    os.mkdir(decoding_path)\n",
    "\n",
    "    # decoding\n",
    "    inference_pipeline = pipeline(\n",
    "        task=Tasks.auto_speech_recognition,\n",
    "        model=params[\"model_dir\"],\n",
    "        output_dir=decoding_path,\n",
    "        batch_size=64\n",
    "    )\n",
    "    audio_in = os.path.join(params[\"test_data_dir\"], \"wav.scp\")\n",
    "    inference_pipeline(audio_in=audio_in)\n",
    "\n",
    "    # computer CER if GT text is set\n",
    "    text_in = os.path.join(params[\"test_data_dir\"], \"text\")\n",
    "    if os.path.exists(text_in):\n",
    "        text_proc_file = os.path.join(decoding_path, \"1best_recog/token\")\n",
    "        compute_wer(text_in, text_proc_file, os.path.join(decoding_path, \"text.cer\"))\n",
    "        os.system(\"tail -n 3 {}\".format(os.path.join(decoding_path, \"text.cer\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 01:38:32,637 - modelscope - INFO - No subset_name specified, defaulting to the default\n",
      "2023-09-02 01:38:33,220 - modelscope - WARNING - Reusing dataset speech_asr_aishell1_trainsets (/home/lihongji/.cache/modelscope/hub/datasets/speech_asr/speech_asr_aishell1_trainsets/master/data_files)\n",
      "2023-09-02 01:38:33,220 - modelscope - INFO - Generating dataset speech_asr_aishell1_trainsets (/home/lihongji/.cache/modelscope/hub/datasets/speech_asr/speech_asr_aishell1_trainsets/master/data_files)\n",
      "2023-09-02 01:38:33,221 - modelscope - INFO - Reusing cached meta-data file: /home/lihongji/.cache/modelscope/hub/datasets/speech_asr/speech_asr_aishell1_trainsets/master/data_files/84d2248455376a60b4f10107a1c4a3ac\n",
      "2023-09-02 01:38:33,221 - modelscope - INFO - Reusing cached meta-data file: /home/lihongji/.cache/modelscope/hub/datasets/speech_asr/speech_asr_aishell1_trainsets/master/data_files/25158edb524e11376428a1643343653c\n",
      "2023-09-02 01:38:33,222 - modelscope - INFO - Reusing cached meta-data file: /home/lihongji/.cache/modelscope/hub/datasets/speech_asr/speech_asr_aishell1_trainsets/master/data_files/bbff82a2cc4f66385c049317a256bf93\n",
      "/home/lihongji/miniconda3/envs/modelscope/lib/python3.8/site-packages/datasets/utils/experimental.py:36: UserWarning: 'parallel_map' is experimental and might be subject to breaking changes in the future.\n",
      "  warnings.warn(\n",
      "\n",
      "Downloading data files #1: 100%|██████████| 1/1 [00:00<00:00,  4.39obj/s]\n",
      "Downloading data files #0: 100%|██████████| 1/1 [00:00<00:00,  4.50obj/s]\n",
      "\n",
      "Downloading data files #2: 100%|██████████| 1/1 [00:00<00:00,  4.25obj/s]\n",
      "Computing checksums: 100%|██████████| 3/3 [00:14<00:00,  4.84s/it]\n",
      "Extracting data files #1: 100%|██████████| 1/1 [00:00<00:00, 191.84obj/s]\n",
      "\n",
      "Extracting data files #0: 100%|██████████| 1/1 [00:00<00:00, 166.78obj/s]\n",
      "Extracting data files #2: 100%|██████████| 1/1 [00:00<00:00, 261.21obj/s]\n",
      "2023-09-02 01:38:49,520 - modelscope - INFO - Model revision not specified, use the latest revision: v1.2.1\n",
      "2023-09-02 01:38:50,372 - modelscope - INFO - Model revision not specified, use the latest revision: v1.2.1\n",
      "2023-09-02 01:38:50,681 - modelscope - INFO - Set workdir to ./checkpoint\n",
      "2023-09-02 01:38:50,888 - modelscope - INFO - Model revision not specified, use the latest revision: v1.2.1\n",
      "usage: Task related config [-h] [--config CONFIG]\n",
      "                           [--frontend {default,sliding_window,s3prl,fused,wav_frontend,multichannelfrontend}]\n",
      "                           [--frontend_conf FRONTEND_CONF]\n",
      "                           [--specaug {specaug,specaug_lfr,None}]\n",
      "                           [--specaug_conf SPECAUG_CONF]\n",
      "                           [--normalize {global_mvn,utterance_mvn,None}]\n",
      "                           [--normalize_conf NORMALIZE_CONF]\n",
      "                           [--model {asr,uniasr,paraformer,paraformer_online,paraformer_bert,bicif_paraformer,contextual_paraformer,neatcontextual_paraformer,mfcca,timestamp_prediction,rnnt,rnnt_unified,sa_asr,bat}]\n",
      "                           [--model_conf MODEL_CONF]\n",
      "                           [--encoder {conformer,transformer,rnn,sanm,sanm_chunk_opt,data2vec_encoder,branchformer,e_branchformer,mfcca_enc,chunk_conformer}]\n",
      "                           [--encoder_conf ENCODER_CONF]\n",
      "                           [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,fsmn_scama_opt,paraformer_decoder_sanm,paraformer_decoder_san,contextual_paraformer_decoder,sa_decoder}]\n",
      "                           [--decoder_conf DECODER_CONF]\n",
      "                           [--predictor {cif_predictor,ctc_predictor,cif_predictor_v2,cif_predictor_v3,bat_predictor,None}]\n",
      "                           [--predictor_conf PREDICTOR_CONF]\n",
      "                           [--encoder2 {conformer,transformer,rnn,sanm,sanm_chunk_opt}]\n",
      "                           [--encoder2_conf ENCODER2_CONF]\n",
      "                           [--decoder2 {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,fsmn_scama_opt,paraformer_decoder_sanm}]\n",
      "                           [--decoder2_conf DECODER2_CONF]\n",
      "                           [--predictor2 {cif_predictor,ctc_predictor,cif_predictor_v2,None}]\n",
      "                           [--predictor2_conf PREDICTOR2_CONF]\n",
      "                           [--stride_conv {stride_conv1d,None}]\n",
      "                           [--stride_conv_conf STRIDE_CONV_CONF]\n",
      "                           [--rnnt_decoder {rnnt,None}]\n",
      "                           [--rnnt_decoder_conf RNNT_DECODER_CONF]\n",
      "                           [--joint_network {joint_network,None}]\n",
      "                           [--joint_network_conf JOINT_NETWORK_CONF]\n",
      "                           [--asr_encoder {conformer,transformer,rnn,sanm,sanm_chunk_opt,data2vec_encoder,mfcca_enc}]\n",
      "                           [--asr_encoder_conf ASR_ENCODER_CONF]\n",
      "                           [--spk_encoder {resnet34_diar}]\n",
      "                           [--spk_encoder_conf SPK_ENCODER_CONF]\n",
      "                           [--split_with_space SPLIT_WITH_SPACE]\n",
      "                           [--seg_dict_file SEG_DICT_FILE]\n",
      "                           [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]\n",
      "                           [--cmvn_file CMVN_FILE] [--output_dir OUTPUT_DIR]\n",
      "                           [--ngpu NGPU] [--seed SEED] [--task_name TASK_NAME]\n",
      "                           [--dist_backend DIST_BACKEND]\n",
      "                           [--dist_init_method DIST_INIT_METHOD]\n",
      "                           [--dist_world_size DIST_WORLD_SIZE]\n",
      "                           [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]\n",
      "                           [--dist_master_addr DIST_MASTER_ADDR]\n",
      "                           [--dist_master_port DIST_MASTER_PORT]\n",
      "                           [--dist_launcher {slurm,mpi,None}]\n",
      "                           [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]\n",
      "                           [--unused_parameters UNUSED_PARAMETERS]\n",
      "                           [--gpu_id GPU_ID] [--cudnn_enabled CUDNN_ENABLED]\n",
      "                           [--cudnn_benchmark CUDNN_BENCHMARK]\n",
      "                           [--cudnn_deterministic CUDNN_DETERMINISTIC]\n",
      "                           [--max_epoch MAX_EPOCH] [--max_update MAX_UPDATE]\n",
      "                           [--batch_interval BATCH_INTERVAL]\n",
      "                           [--patience PATIENCE]\n",
      "                           [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]\n",
      "                           [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]\n",
      "                           [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]\n",
      "                           [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]\n",
      "                           [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]\n",
      "                           [--grad_clip GRAD_CLIP]\n",
      "                           [--grad_clip_type GRAD_CLIP_TYPE]\n",
      "                           [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]\n",
      "                           [--resume RESUME]\n",
      "                           [--train_dtype {float16,float32,float64}]\n",
      "                           [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]\n",
      "                           [--use_tensorboard USE_TENSORBOARD]\n",
      "                           [--init_param INIT_PARAM]\n",
      "                           [--ignore_init_mismatch IGNORE_INIT_MISMATCH]\n",
      "                           [--freeze_param FREEZE_PARAM]\n",
      "                           [--dataset_type DATASET_TYPE]\n",
      "                           [--dataset_conf DATASET_CONF] [--data_dir DATA_DIR]\n",
      "                           [--train_set TRAIN_SET] [--valid_set VALID_SET]\n",
      "                           [--data_file_names DATA_FILE_NAMES]\n",
      "                           [--speed_perturb SPEED_PERTURB [SPEED_PERTURB ...]]\n",
      "                           [--use_preprocessor USE_PREPROCESSOR]\n",
      "                           [--optim OPTIM] [--optim_conf OPTIM_CONF]\n",
      "                           [--scheduler SCHEDULER]\n",
      "                           [--scheduler_conf SCHEDULER_CONF]\n",
      "                           [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]\n",
      "                           [--token_list TOKEN_LIST]\n",
      "                           [--token_type {bpe,char,word}]\n",
      "                           [--bpemodel BPEMODEL]\n",
      "                           [--cleaner {None,tacotron,jaconv,vietnamese}]\n",
      "                           [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_english_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]\n",
      "                           [--use_pai USE_PAI] [--simple_ddp SIMPLE_DDP]\n",
      "                           [--num_worker_count NUM_WORKER_COUNT]\n",
      "                           [--access_key_id ACCESS_KEY_ID]\n",
      "                           [--access_key_secret ACCESS_KEY_SECRET]\n",
      "                           [--endpoint ENDPOINT] [--bucket_name BUCKET_NAME]\n",
      "                           [--oss_bucket OSS_BUCKET]\n",
      "                           [--enable_lora ENABLE_LORA] [--lora_bias LORA_BIAS]\n",
      "Task related config: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9019 --control=9017 --hb=9016 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"ea298208-f753-413c-bf0f-1300aa5e696d\" --shell=9018 --transport=\"tcp\" --iopub=9020\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lihongji/miniconda3/envs/modelscope/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from funasr.utils.modelscope_param import modelscope_args\n",
    "params = modelscope_args(model=\"damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\")\n",
    "params.output_dir = \"./checkpoint\"                      # 模型保存路径\n",
    "params.data_path = \"speech_asr_aishell1_trainsets\"      # 数据路径，可以为modelscope中已上传数据，也可以是本地数据\n",
    "params.dataset_type = \"small\"                           # 小数据量设置small，若数据量大于1000小时，请使用large\n",
    "params.batch_bins = 2000                                # batch size，如果dataset_type=\"small\"，batch_bins单位为fbank特征帧数，如果dataset_type=\"large\"，batch_bins单位为毫秒，\n",
    "params.max_epoch = 50                                   # 最大训练轮数\n",
    "params.lr = 0.00005                                     # 设置学习率\n",
    "\n",
    "modelscope_finetune(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
